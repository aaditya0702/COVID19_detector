{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfjT0HNh5XOT",
        "colab_type": "text"
      },
      "source": [
        "Instructions:\n",
        "1. Clone the repository. \n",
        "2. Run the cells for data preprocessing.\n",
        "2. For all pre-trained models, run the code cell corresponding to the one you wish to train.\n",
        "3. Create a data augmentation object.\n",
        "4. Compile the model.\n",
        "5. Train the network.\n",
        "6. Evaluate the model's metrics.\n",
        "7. For the basic CNN, all code required to train is within the block (except for the data augmentation object.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9lQKs1ykQWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Clone a private Github repository.\n",
        "\n",
        "import os\n",
        "from getpass import getpass\n",
        "import urllib\n",
        "\n",
        "user = input('User name: ')\n",
        "password = getpass('Password: ')\n",
        "password = urllib.parse.quote(password) \n",
        "repo_name = input('Repo name: ')\n",
        "\n",
        "cmd_string = 'git clone https://{0}:{1}@github.com/{0}/{2}.git'.format(user, password, repo_name)\n",
        "\n",
        "os.system(cmd_string)\n",
        "cmd_string, password = \"\", \"\" "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asq1Zi65Z743",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import the necessary libraries.\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications import ResNet101\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Convolution2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6-YkHlzmPff",
        "colab_type": "text"
      },
      "source": [
        "**Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDlG3a_dbPAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define the categories of x-rays. \n",
        "class_names = ['covid', 'normal', 'pneumonia']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Do38ak51esaZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Path of the directories where the pictures are stored.\n",
        "covidDir = \"/content/coronavirus_detector/dataset/covid\"\n",
        "pneumoniaDir = \"/content/coronavirus_detector/dataset/pneumonia\"\n",
        "normalDir = \"/content/coronavirus_detector/dataset/normal\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aP4Agp47etWI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to load and resize the pictures and return them along with labels.\n",
        "def load_images_from_folder(folder):\n",
        "  images = []\n",
        "  labels = []\n",
        "  for filename in os.listdir(folder):\n",
        "    img = cv2.imread(os.path.join(folder, filename))                \n",
        "    img = cv2.resize(img, (144, 144))                                 #Resize to 144 x 144\n",
        "    images.append(img)\n",
        "    label = (os.path.join(folder, filename)).split(os.path.sep)[-2]\n",
        "    if label=='covid':\n",
        "      labels.append(1)                                                #Covid-19 positive x-rays labelled 1\n",
        "    else:\n",
        "      labels.append(0)                                                #Healthy and non-Covid pneumonia x-rays labelled 0\n",
        "  return images, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z--NJmUWy9I8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load the images from the respective directories.\n",
        "\n",
        "images_covid, labels_covid = load_images_from_folder(covidDir)\n",
        "images_normal, labels_normal = load_images_from_folder(normalDir)\n",
        "images_pneu, labels_pneu = load_images_from_folder(pneumoniaDir)\n",
        "\n",
        "\n",
        "#Display the number of x-rays from each category.\n",
        "\n",
        "print(len(labels_covid))\n",
        "print(len(labels_normal))\n",
        "print(len(labels_pneu))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-N1qZgaZiZk7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create the test dataset with 100 x-rays from each category to ensure balance.\n",
        "\n",
        "test_images = images_covid[:100]\n",
        "test_labels = labels_covid[:100]\n",
        "test_images.extend(images_normal[:100])\n",
        "test_labels.extend(labels_normal[:100])\n",
        "test_images.extend(images_pneu[:100])\n",
        "test_labels.extend(labels_pneu[:100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8-LQk4oiZie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create the validation dataset in the same manner as test dataset.\n",
        "\n",
        "valid_images = images_covid[-100:]\n",
        "valid_labels = labels_covid[-100:]\n",
        "valid_images.extend(images_normal[-100:])\n",
        "valid_labels.extend(labels_normal[-100:])\n",
        "valid_images.extend(images_pneu[-100:])\n",
        "valid_labels.extend(labels_pneu[-100:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1p2KNWFinKP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create the training dataset with the remaining x-rays.\n",
        "\n",
        "train_images = images_covid[100:-100]\n",
        "train_labels = labels_covid[100:-100]\n",
        "train_images.extend(images_normal[100:-100])\n",
        "train_labels.extend(labels_normal[100:-100])\n",
        "train_images.extend(images_pneu[100:-100])\n",
        "train_labels.extend(labels_pneu[100:-100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_zf05zb1vIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Convert the datasets to numpy arrays.\n",
        "X_test = np.array(test_images)\n",
        "y_test = np.array(test_labels)\n",
        "\n",
        "X_train = np.array(train_images)\n",
        "y_train = np.array(train_labels)\n",
        "\n",
        "X_valid = np.array(valid_images)\n",
        "y_valid = np.array(valid_labels)\n",
        "\n",
        "\n",
        "#Normalize the images.\n",
        "X_test = X_test / 255.0\n",
        "X_train = X_train / 255.0\n",
        "X_valid = X_valid / 255.0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QLL-azyUStP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Display the number of Covid-19 positive x-rays in each dataset.\n",
        "\n",
        "print(np.count_nonzero(y_train == 1))\n",
        "print(len(y_train))\n",
        "print(np.count_nonzero(y_test == 1))\n",
        "print(len(y_test))\n",
        "print(np.count_nonzero(y_valid == 1))\n",
        "print(len(y_valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fj1R_CIZmXVk",
        "colab_type": "text"
      },
      "source": [
        "**Model Definitions and Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IX2pupENhpSa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define a basic CNN model.\n",
        "\n",
        "def getModel(optimizer):\n",
        "  model = Sequential()\n",
        "  model.add(Convolution2D(32, (3, 3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same', input_shape = (144, 144, 3)))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation = 'relu', kernel_initializer = 'he_uniform'))\n",
        "  model.add(Dense(1, activation = 'sigmoid'))\n",
        "  return model\n",
        "\n",
        "#Define the optimizer.\n",
        "opt = keras.optimizers.SGD(lr = 0.001, momentum = 0.9)\n",
        "model = getModel(opt)\n",
        "\n",
        "#Compile the model\n",
        "model.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "#Train the model along with cross-validation.\n",
        "model.fit(\n",
        "trainAug.flow(X_train, y_train, batch_size=BS),\n",
        "steps_per_epoch=len(X_train) // BS,\n",
        "validation_data=(X_valid, y_valid),\n",
        "validation_steps=len(X_valid) // BS,\n",
        "epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqM7Wf8a9tp5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Use ResNet-50 with ImageNet weights.\n",
        "\n",
        "baseModel = ResNet50(weights = \"imagenet\", include_top = False, input_tensor = Input(shape = (144, 144, 3)))\n",
        "headModel = baseModel.output\n",
        "headModel = AveragePooling2D(pool_size=(4, 4))(headModel)\n",
        "headModel = Flatten()(headModel)\n",
        "headModel = Dense(64, activation = 'relu')(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(1, activation = 'sigmoid')(headModel)\n",
        "for layer in baseModel.layers:\n",
        "  layer.trainable = False\n",
        "model = Model(inputs = baseModel.input, outputs = headModel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRT8IbDJhPoD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Use VGG-16.\n",
        "\n",
        "baseModel = VGG16(weights = \"imagenet\", include_top = False, input_tensor = Input(shape = (144, 144, 3)))\n",
        "headModel = baseModel.output\n",
        "headModel = AveragePooling2D(pool_size=(4, 4))(headModel)\n",
        "headModel = Flatten()(headModel)\n",
        "headModel = Dense(64, activation = 'relu')(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(1, activation = 'sigmoid')(headModel)\n",
        "for layer in baseModel.layers:\n",
        "  layer.trainable = False\n",
        "model = Model(inputs = baseModel.input, outputs = headModel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAIhzniY2CTM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Use ResNet-101.\n",
        "\n",
        "baseModel = ResNet101(weights = \"imagenet\", include_top = False, input_tensor = Input(shape = (144, 144, 3)))\n",
        "headModel = baseModel.output\n",
        "headModel = AveragePooling2D(pool_size=(4, 4))(headModel)\n",
        "headModel = Flatten()(headModel)\n",
        "headModel = Dense(64, activation = 'relu')(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(1, activation = 'sigmoid')(headModel)\n",
        "for layer in baseModel.layers:\n",
        "  layer.trainable = False\n",
        "model = Model(inputs = baseModel.input, outputs = headModel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ls-JKdh13Z7v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Use VGG-19.\n",
        "\n",
        "baseModel = VGG19(weights = \"imagenet\", include_top = False, input_tensor = Input(shape = (144, 144, 3)))\n",
        "headModel = baseModel.output\n",
        "headModel = AveragePooling2D(pool_size=(4, 4))(headModel)\n",
        "headModel = Flatten()(headModel)\n",
        "headModel = Dense(64, activation = 'relu')(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(1, activation = 'sigmoid')(headModel)\n",
        "for layer in baseModel.layers:\n",
        "  layer.trainable = False\n",
        "model = Model(inputs = baseModel.input, outputs = headModel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9EvVYvv3F0A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define parameters.\n",
        "\n",
        "INIT_LR = 1e-3\n",
        "EPOCHS = 25\n",
        "BS = 8\n",
        "\n",
        "#Create a data augmentation object.\n",
        "\n",
        "trainAug = ImageDataGenerator(\n",
        "\trotation_range=15,\n",
        "\tfill_mode=\"nearest\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3eGGaNk2QSN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compile the chosen model.\n",
        "opt = tf.keras.optimizers.Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGypl18o2MN2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Train the model.\n",
        "\n",
        "print(\"Training model.\")\n",
        "model.fit(\n",
        "trainAug.flow(X_train, y_train, batch_size=BS),\n",
        "steps_per_epoch=len(X_train) // BS,\n",
        "validation_data=(X_valid, y_valid),\n",
        "validation_steps=len(X_valid) // BS,\n",
        "epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDbS4vLCmkS8",
        "colab_type": "text"
      },
      "source": [
        "**Evaluation Metrics**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQEsTo4yAB_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Evaluate the model on the Test dataset.\n",
        "\n",
        "model.evaluate(X_test, y_test, verbose = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMBmEYfKwRfm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Evaluate other metrics of the model.\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = y_pred[:,0]                        #Creating a single array of predictions\n",
        "\n",
        "for i in range(len(y_pred)):\n",
        "  if(y_pred[i] > 0.5):                      #Threshold value of 0.5\n",
        "    y_pred[i] = 1\n",
        "  else:\n",
        "    y_pred[i] = 0\n",
        "\n",
        "#print(y_pred)                              #Uncomment line to print predictions \n",
        "print(\"Accuracy Score - \", accuracy_score(y_test, y_pred)) \n",
        "print(\"Precision Score - \", precision_score(y_test, y_pred))\n",
        "print(\"Recall Score - \", recall_score(y_test, y_pred))         #F1 Score\n",
        "print(\"F1 Score - \",f1_score(y_test, y_pred))                 \n",
        "print(\"Cohen Kappa Score - \",cohen_kappa_score(y_test, y_pred))\n",
        "print(\"ROC AUC Score - \",roc_auc_score(y_test, y_pred))\n",
        "print(\"Confusion Matrix - \",confusion_matrix(y_test, y_pred))     #Confusion Matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ngpc74V3YHXn",
        "colab_type": "text"
      },
      "source": [
        "1. Basic Model:\n",
        "\n",
        "  Accuracy: 90.33%\n",
        "\n",
        "  F1 Score: 0.83\n",
        "\n",
        "2. ResNet50:\n",
        "\n",
        "  Accuracy: 81.67%\n",
        "\n",
        "  F1 Score: 0.62\n",
        "\n",
        "3. VGG16:\n",
        "  \n",
        "  Accuracy: 97.33%\n",
        "  \n",
        "  F1 Score: 0.96\n",
        "\n",
        "4. ResNet101:\n",
        "  \n",
        "  Accuracy: 90%\n",
        "  \n",
        "  F1 Score: 0.83\n",
        "\n",
        "5. VGG19:\n",
        "  \n",
        "  Accuracy: 94.67%\n",
        "  \n",
        "  F1 Score: 0.91\n",
        "\n"
      ]
    }
  ]
}